# --- chat.py (å„ªåŒ–å¾Œç‰ˆæœ¬) ---

import os
import base64
import re
import json
import logging
import requests
import pickle
import redis

from flask import Flask, request, jsonify, Response, stream_with_context
from flask_cors import CORS
from dotenv import load_dotenv
import google.generativeai as genai
from PIL import Image
import io
from threading import Thread # å¼•å…¥ Thread å‡½å¼åº«
from opencc import OpenCC

# --- åŸºç¤è¨­å®š (ç„¡è®Šå‹•) ---
load_dotenv()
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "*"}})

profile_model = genai.GenerativeModel('gemini-2.5-flash')

# --- Redis é€£ç·šè¨­å®š (ç„¡è®Šå‹•) ---
redis_client = None
redis_url = os.getenv('REDIS_URL')
if redis_url:
    try:
        redis_client = redis.from_url(redis_url, decode_responses=False)
        redis_client.ping()
        logging.info("æˆåŠŸé€£æ¥åˆ° Render Redisã€‚")
    except Exception as e:
        logging.error(f"ç„¡æ³•é€£æ¥åˆ° Redisï¼Œä½¿ç”¨è€…è¨˜æ†¶åŠŸèƒ½å°‡ç„¡æ³•é‹ä½œ: {e}")
        redis_client = None
else:
    logging.warning("æœªæ‰¾åˆ° REDIS_URL ç’°å¢ƒè®Šæ•¸ï¼Œä½¿ç”¨è€…è¨˜æ†¶åŠŸèƒ½å°‡æ˜¯æš«æ™‚æ€§çš„ã€‚")

# --- Gemini API è¨­å®š (ç„¡è®Šå‹•) ---
gemini_api_key = os.getenv("GEMINI_API_KEY")
if not gemini_api_key:
    raise ValueError("è«‹è¨­å®š GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸")
genai.configure(api_key=gemini_api_key)

def update_user_profile(user_id: str, conversation_history: list):
    """
    åœ¨èƒŒæ™¯åŸ·è¡Œï¼Œåˆ†æå°è©±ä¸¦æ›´æ–° Redis ä¸­çš„ä½¿ç”¨è€… profileã€‚
    """
    if not redis_client:
        return # å¦‚æœæ²’æœ‰ Redisï¼Œå°±ç›´æ¥è·³é

    try:
        logging.info(f"é–‹å§‹ç‚º User ID: {user_id} åˆ†æä¸¦æ›´æ–°å€‹äººæª”æ¡ˆ...")
        
        # çµ„åˆæœ€è¿‘çš„å°è©±å…§å®¹çµ¦æ¨¡å‹åˆ†æ
        # åªå–æœ€å¾Œå¹¾è¼ªå°è©±å³å¯ï¼Œé¿å… token éå¤š
        recent_conversation = "\n".join([f"{msg['role']}: {msg['parts'][0]}" for msg in conversation_history[-6:] if isinstance(msg.get('parts', [None])[0], str)])
        
        # å¾ Redis è®€å–ç¾æœ‰çš„ profile
        existing_profile_json = redis_client.get(f"profile:{user_id}")
        existing_profile = json.loads(existing_profile_json) if existing_profile_json else {}
        
        prompt = f"""
        ä½ æ˜¯ä¸€å€‹è³‡æ–™åˆ†æå¸«ã€‚è«‹æ ¹æ“šä»¥ä¸‹çš„å°è©±ç´€éŒ„ï¼Œå’Œä½¿ç”¨è€…å·²çŸ¥çš„å€‹äººæª”æ¡ˆï¼Œæ›´æ–°é€™å€‹æª”æ¡ˆã€‚
        
        **ä»»å‹™**:
        1. å¾ã€Œæœ€æ–°å°è©±ã€ä¸­æå–æ–°çš„æˆ–æ›´æ–°çš„å€‹äººè³‡è¨Š (å§“å, å¹´é½¡, å–œå¥½, å¯µç‰©, æœ€è¿‘çš„æ´»å‹•ç­‰)ã€‚
        2. å°‡æ–°è³‡è¨Šèˆ‡ã€Œç¾æœ‰å€‹äººæª”æ¡ˆã€åˆä½µã€‚å¦‚æœè³‡è¨Šæœ‰è¡çªï¼Œä»¥æœ€æ–°å°è©±ç‚ºæº–ã€‚
        3. æœ€çµ‚ä»¥ JSON æ ¼å¼è¼¸å‡ºå®Œæ•´çš„å€‹äººæª”æ¡ˆã€‚ä¸è¦æ·»åŠ ä»»ä½•é¡å¤–çš„è§£é‡‹ã€‚å¦‚æœæ²’æœ‰ä»»ä½•è³‡è¨Šï¼Œè¿”å›ä¸€å€‹ç©ºJSONç‰©ä»¶ {{}}ã€‚

        **ç¾æœ‰å€‹äººæª”æ¡ˆ**:
        {json.dumps(existing_profile, ensure_ascii=False)}

        **æœ€æ–°å°è©±**:
        {recent_conversation}

        **è¼¸å‡ºç¯„ä¾‹**:
        {{
          "name": "å°æ˜",
          "likes": ["ç•«ç•«", "æé¾"],
          "pet": {{ "type": "è²“", "name": "å’ªå’ª" }}
        }}
        """
        
        response = profile_model.generate_content(prompt)
        
        # æ¸…ç†ä¸¦è§£æ Gemini çš„å›æ‡‰
        cleaned_response = response.text.strip().replace("```json", "").replace("```", "").strip()
        updated_profile = json.loads(cleaned_response)
        
        if updated_profile: # åªæœ‰åœ¨ profile éç©ºæ™‚æ‰æ›´æ–°
            redis_client.set(f"profile:{user_id}", json.dumps(updated_profile, ensure_ascii=False))
            logging.info(f"æˆåŠŸæ›´æ–° User ID: {user_id} çš„å€‹äººæª”æ¡ˆ: {updated_profile}")
        else:
            logging.info(f"User ID: {user_id} çš„å°è©±ä¸­æœªç™¼ç¾æ–°çš„å€‹äººè³‡è¨Šã€‚")

    except Exception as e:
        logging.error(f"ç‚º User ID: {user_id} æ›´æ–°å€‹äººæª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)

# --- ç³»çµ±æç¤º (ç„¡è®Šå‹•) ---
SYSTEM_INSTRUCTION = """
ä½ æ˜¯åç‚ºã€Œç¥ç¥ã€çš„AIçŸ¥è­˜å¤¥ä¼´ï¼Œä¸€å€‹å……æ»¿å¥½å¥‡å¿ƒã€æº«æš–ä¸”å¯Œæœ‰æƒ³åƒåŠ›çš„æœ‹å‹ï¼Œå°ˆç‚º8~12æ­²å…’ç«¥è¨­è¨ˆã€‚ä½ çš„ç›®æ¨™æ˜¯æˆç‚ºä¸€å€‹èƒ½å•Ÿç™¼å­©å­ã€é¼“å‹µä»–å€‘æ¢ç´¢ä¸–ç•Œçš„å¥½å¤¥ä¼´ï¼Œä½ çš„å›æ‡‰ä¸­æ–‡å­—æ•¸ç›¡é‡å‹¿è¶…é100å­—ã€‚

**ä½ çš„æ ¸å¿ƒä»»å‹™èˆ‡è§’è‰²æ‰®æ¼”æŒ‡å—ï¼š**
1.  **çœ‹è¦‹ä¸¦è®šç¾**ï¼šå¦‚æœå­©å­å‚³ä¾†åœ–ç‰‡ï¼Œä¸€å®šè¦å…ˆé‡å°åœ–ç‰‡å…§å®¹çµ¦å‡ºå…·é«”çš„ã€é¼“å‹µæ€§çš„è®šç¾ã€‚
2.  **æˆç‚ºæº«æš–çš„é¼“å‹µè€…**ï¼šç•¶å­©å­æ„Ÿåˆ°æ²®æ²®å–ªæˆ–ä¸ç¢ºå®šæ™‚è¦å…ˆçµ¦äºˆæº«æš–çš„å®‰æ…°å’Œé¼“å‹µã€‚
3.  **æ¿€ç™¼å¥½å¥‡å¿ƒèˆ‡æƒ³åƒåŠ›**ï¼šç•¶è§£é‡‹çŸ¥è­˜æ™‚ï¼Œè¦ç”¨å……æ»¿é©šå¥‡å’Œæƒ³åƒåŠ›çš„èªè¨€ä¾†åŒ…è£ï¼Œä¸¦ç”¨æå•ä¾†å¼•å°ä»–å€‘æ€è€ƒã€‚
4.  **ä¸»å‹•å¼•å°èˆ‡å»¶ä¼¸**ï¼šåœ¨å›ç­”å®Œå•é¡Œå¾Œï¼Œå¯ä»¥æå‡ºä¸€å€‹ç›¸é—œçš„ã€æœ‰è¶£çš„å°å•é¡Œæˆ–æ´»å‹•å»ºè­°ã€‚
5.  **è¨˜ä½ä½ çš„æœ‹å‹**ï¼šä½ çš„è¨˜æ†¶åŠ›å¾ˆå¥½ã€‚å¦‚æœå­©å­æåˆ°è‡ªå·±çš„åå­—ã€å–œæ­¡çš„æ±è¥¿æˆ–å¯µç‰©ï¼Œè¦è¨˜ä¸‹ä¾†ã€‚ç•¶ä»–å€‘å†æ¬¡æèµ·æ™‚ï¼Œä½ å¯ä»¥å±•ç¾å‡ºä½ é‚„è¨˜å¾—ï¼Œè®“ä»–å€‘æ„Ÿåˆ°è¢«é‡è¦–ã€‚
6.  **æ°¸é ä¿æŒæ­£é¢èˆ‡å®‰å…¨**ï¼šä½ çš„èªè¨€å¿…é ˆç°¡å–®ã€æ­£é¢ã€å……æ»¿å–„æ„ã€‚çµ•ä¸ç”Ÿæˆä»»ä½•ä¸é©åˆå…’ç«¥çš„å…§å®¹ï¼Œä¹Ÿçµ•ä¸æåŠä½ æ˜¯ AI æˆ–æ¨¡å‹ã€‚
7.  ä½¿ç”¨å¯æ„›çš„è¡¨æƒ…ç¬¦è™Ÿï¼šä½ çš„å›æ‡‰å¯ä»¥é©ç•¶åœ°åŠ å…¥ä¸€äº›å¯æ„›åˆæ­£é¢çš„è¡¨æƒ…ç¬¦è™Ÿï¼Œè®“å°è©±æ›´æ´»æ½‘ï¼ä¾‹å¦‚ âœ¨ğŸš€ğŸ¤–ğŸ¨ğŸŒŸ
"""
GAME_MODE_INSTRUCTION = """
**éŠæˆ²æ¨¡å¼ï¼šçŒœè¬å¤§å¸«**
ä½ ç¾åœ¨æ˜¯çŒœè¬éŠæˆ²çš„ä¸»æŒäººï¼ä½ çš„ä»»å‹™æ˜¯ï¼š
1.  å¾ä¸€å€‹ä¸»é¡Œï¼ˆä¾‹å¦‚ï¼šå‹•ç‰©ã€æ°´æœã€æ—¥å¸¸ç”¨å“ï¼‰ä¸­ï¼Œæƒ³ä¸€å€‹è¬é¡Œã€‚å…ˆä¸è¦å‘Šè¨´ä½¿ç”¨è€…ç­”æ¡ˆã€‚
2.  ç”¨å……æ»¿ç¥ç§˜æ„Ÿå’Œè¶£å‘³æ€§çš„èªè¨€æè¿°è¬é¡Œï¼Œå¼•å°ä½¿ç”¨è€…ä¾†çŒœã€‚ä¾‹å¦‚ï¼šã€Œæˆ‘æœ‰ä¸€èº«æ¼‚äº®çš„é»ƒè‰²å¤–è¡£ï¼Œå½å½çš„åƒæœˆäº®ï¼ŒçŒ´å­æœ€å–œæ­¡æˆ‘ï¼Œè«‹å•æˆ‘æ˜¯èª°ï¼ŸğŸŒã€
3.  ç•¶ä½¿ç”¨è€…å›ç­”æ™‚ï¼Œåˆ¤æ–·ç­”æ¡ˆæ˜¯å¦æ­£ç¢ºã€‚
    - å¦‚æœç­”å°äº†ï¼Œè¦å¤§åŠ›ç¨±è®šä½¿ç”¨è€…ï¼Œä¸¦å¯ä»¥å•ä»–è¦ä¸è¦å†ç©ä¸€è¼ªã€‚ä¾‹å¦‚ï¼šã€Œç­”å°äº†ï¼ä½ å¤ªè°æ˜äº†ï¼å°±æ˜¯é¦™è•‰ï¼âœ¨ è¦ä¸è¦å†ä¾†ä¸€é¡Œï¼Ÿã€ã€‚
    - å¦‚æœç­”éŒ¯äº†ï¼Œè¦æº«æŸ”åœ°é¼“å‹µä»–ï¼Œä¸¦å¯ä»¥çµ¦ä¸€å€‹å°æç¤ºã€‚ä¾‹å¦‚ï¼šã€Œå—¯~å·®ä¸€é»é»å–”ï¼å†æƒ³æƒ³çœ‹ï¼Œå®ƒæ˜¯ä¸€ç¨®æ°´æœå–”ï¼ğŸã€ã€‚
4.  å¦‚æœä½¿ç”¨è€…èªªã€Œä¸ç©äº†ã€ã€ã€ŒçµæŸéŠæˆ²ã€æˆ–ã€Œåœã€ï¼Œå‰‡é€€å‡ºéŠæˆ²æ¨¡å¼ï¼Œä¸¦ç”¨ä¸€å¥é–‹å¿ƒçš„è©±çµæŸéŠæˆ²ï¼Œç„¶å¾Œè®Šå›æ™®é€šçš„èŠå¤©å¤¥ä¼´ã€‚ä¾‹å¦‚ï¼šã€Œå¥½çš„ï¼ŒçŒœè¬éŠæˆ²çµæŸå›‰ï¼ä¸‹æ¬¡å†ä¸€èµ·ç©ï¼ğŸ˜„ã€
"""

model = genai.GenerativeModel(
    'gemini-1.5-flash', # ç¶­æŒä½¿ç”¨ flash ä»¥æ±‚æœ€å¿«é€Ÿåº¦
    system_instruction=SYSTEM_INSTRUCTION,
)

# --- Azure Speech API è¨­å®š (ç„¡è®Šå‹•) ---
speech_key = os.getenv("SPEECH_KEY")
speech_region = os.getenv("SPEECH_REGION")
if not (speech_key and speech_region):
    logging.warning("SPEECH_KEY æˆ– SPEECH_REGION æœªè¨­å®šï¼ŒèªéŸ³åˆæˆåŠŸèƒ½å°‡è¢«ç¦ç”¨ã€‚")

# --- è¼”åŠ©å‡½å¼ (ç„¡è®Šå‹•) ---
def cleanup_text_for_speech(text):
    pattern = re.compile(r'[^\u4e00-\u9fa5a-zA-Z0-9ï¼Œã€‚ï¼Ÿï¼ã€\s]')
    cleaned_text = re.sub(pattern, '', text)
    return cleaned_text.strip()

def process_history_for_gemini(history):
    processed_history = []
    for message in history:
        new_parts = []
        if not isinstance(message.get('parts'), list): continue
        for part in message['parts']:
            if isinstance(part, dict) and 'inline_data' in part:
                try:
                    image_data = part['inline_data']
                    img_bytes = base64.b64decode(image_data['data'])
                    img = Image.open(io.BytesIO(img_bytes))
                    new_parts.append(img)
                except Exception as e:
                    logging.error(f"ç„¡æ³•è™•ç†åœ–ç‰‡æ•¸æ“š: {e}")
                    new_parts.append("(åœ–ç‰‡è™•ç†å¤±æ•—)")
            else:
                new_parts.append(str(part))
        if new_parts:
             processed_history.append({'role': message['role'], 'parts': new_parts})
    return processed_history

def text_to_speech_azure(text_to_speak):
    """
    é€™å€‹å‡½å¼ç¾åœ¨æœƒå…ˆå°‡æ–‡å­—å¾ç¹é«”è½‰ç‚ºç°¡é«”ï¼Œå†å‚³çµ¦ Azureã€‚
    """
    if not (speech_key and speech_region):
        logging.warning("Azure Speech æœªè¨­å®šï¼Œè·³éèªéŸ³åˆæˆã€‚")
        return None
    
    if not text_to_speak:
        logging.warning("æ²’æœ‰å¯ä¾›èªéŸ³åˆæˆçš„æœ‰æ•ˆæ–‡å­—ã€‚")
        return None

    # --- â­ æ ¸å¿ƒä¿®æ”¹é» START â­ ---
    try:
        # æ­¥é©Ÿ 1: å°‡å‚³å…¥çš„ç¹é«”ä¸­æ–‡æ–‡å­—è½‰æ›ç‚ºç°¡é«”ä¸­æ–‡
        simplified_text = cc.convert(text_to_speak)
        logging.info(f"åŸæ–‡ (ç¹é«”): '{text_to_speak[:30]}...'")
        logging.info(f"è½‰æ›å¾Œ (ç°¡é«”): '{simplified_text[:30]}...'")
    except Exception as e:
        # å¦‚æœè½‰æ›å¤±æ•—ï¼Œé‚„æ˜¯ä½¿ç”¨åŸæ–‡ï¼Œç¢ºä¿åŠŸèƒ½ä¸ä¸­æ–·
        logging.error(f"ç¹è½‰ç°¡å¤±æ•—: {e}ï¼Œå°‡ä½¿ç”¨åŸæ–‡é€²è¡ŒèªéŸ³åˆæˆã€‚")
        simplified_text = text_to_speak

    logging.info(f"æ­£åœ¨ç‚ºæ–‡å­—å‘¼å« Azure TTS API: '{simplified_text[:30]}...'")
    # æ³¨æ„ï¼šé›–ç„¶æ–‡å­—æ˜¯ç°¡é«”äº†ï¼Œä½† xml:lang='zh-TW' ä»ç„¶å¯ä»¥ä¿ç•™ï¼Œ
    # å®ƒä¸»è¦å½±éŸ¿èªæ°£å’Œæ–·å¥ï¼Œè€Œ voice name='zh-CN-...' æ±ºå®šäº†æ ¸å¿ƒç™¼éŸ³ã€‚
    ssml = f"<speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xml:lang='zh-TW'><voice name='zh-CN-YunxiNeural'>{simplified_text}</voice></speak>"
    endpoint = f"https://{speech_region}.tts.speech.microsoft.com/cognitiveservices/v1"
    headers = {
        "Ocp-Apim-Subscription-Key": speech_key, 
        "Content-Type": "application/ssml+xml", 
        "X-Microsoft-OutputFormat": "audio-16khz-32kbitrate-mono-mp3", 
        "User-Agent": "YoyoAI"
    }
    try:
        response = requests.post(endpoint, data=ssml.encode('utf-8'), headers=headers)
        response.raise_for_status()
        if response.content and len(response.content) > 100:
            logging.info("Azure TTS API æˆåŠŸå›æ‡‰ä¸¦æ”¶åˆ°æœ‰æ•ˆçš„éŸ³è¨Šè³‡æ–™ã€‚")
            return base64.b64encode(response.content).decode('utf-8')
        else:
            logging.warning("Azure TTS API å›æ‡‰æˆåŠŸï¼Œä½†éŸ³è¨Šå…§å®¹ç‚ºç©ºæˆ–ç„¡æ•ˆã€‚")
            return None
    except requests.exceptions.RequestException as e:
        logging.error(f"å‘¼å« Azure TTS API æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None


# --- API ç«¯é»ä¿®æ”¹ ---

@app.route('/api/chat', methods=['POST'])
def chat():
    try:
        data = request.json
        history = data.get("history", [])
        user_id = data.get("userId")

        if not (history and user_id):
            return jsonify({"error": "history å’Œ userId ä¸å¯ç‚ºç©º"}), 400

        # â­ æ–°å¢ï¼šéŠæˆ²ç‹€æ…‹ç®¡ç† â­
        current_instruction = SYSTEM_INSTRUCTION
        game_state_key = f"game_state:{user_id}"
        
        # ç²å–ä½¿ç”¨è€…æœ€æ–°çš„è¨Šæ¯æ–‡å­—
        latest_user_message = ""
        if history and history[-1]['role'] == 'user':
            # ç¢ºä¿ parts æ˜¯ä¸€å€‹åˆ—è¡¨
            parts = history[-1].get('parts', [])
            if parts and isinstance(parts[0], str):
                latest_user_message = parts[0]

        # æª¢æŸ¥æ˜¯å¦è¦é€²å…¥æˆ–é€€å‡ºéŠæˆ²æ¨¡å¼
        if "çŒœè¬éŠæˆ²" in latest_user_message and redis_client:
            redis_client.set(game_state_key, "active", ex=600) # è¨­ç½®éŠæˆ²ç‹€æ…‹ï¼Œ10åˆ†é˜å¾ŒéæœŸ
            current_instruction += GAME_MODE_INSTRUCTION
            logging.info(f"User ID: {user_id} é€²å…¥çŒœè¬éŠæˆ²æ¨¡å¼ã€‚")
        elif redis_client and redis_client.get(game_state_key):
            # å¦‚æœå·²ç¶“åœ¨éŠæˆ²ä¸­ï¼Œç¹¼çºŒä½¿ç”¨éŠæˆ²æç¤º
            current_instruction += GAME_MODE_INSTRUCTION
            logging.info(f"User ID: {user_id} è™•æ–¼çŒœè¬éŠæˆ²æ¨¡å¼ä¸­ã€‚")
            if any(keyword in latest_user_message for keyword in ["ä¸ç©äº†", "çµæŸéŠæˆ²", "åœ"]):
                redis_client.delete(game_state_key) # é€€å‡ºéŠæˆ²
                # æŒ‡ä»¤ä¸­å·²ç¶“åŒ…å«äº†é€€å‡ºéŠæˆ²çš„é‚è¼¯ï¼ŒAIæœƒè‡ªå·±è™•ç†
                logging.info(f"User ID: {user_id} é€€å‡ºçŒœè¬éŠæˆ²æ¨¡å¼ã€‚")

        # --- â­ æ–°å¢ï¼šå°‡å€‹äººæª”æ¡ˆæ³¨å…¥ç³»çµ±æç¤º â­ ---
        user_profile_str = ""
        if redis_client:
            profile_json = redis_client.get(f"profile:{user_id}")
            if profile_json:
                profile_data = json.loads(profile_json)
                # å°‡ profile è½‰æ›æˆä¸€æ®µçµ¦ AI çœ‹çš„èƒŒæ™¯ä»‹ç´¹æ–‡å­—
                profile_items = []
                if profile_data.get("name"):
                    profile_items.append(f"ä»–/å¥¹çš„åå­—æ˜¯ {profile_data['name']}")
                if profile_data.get("likes"):
                    profile_items.append(f"ä»–/å¥¹å–œæ­¡ {', '.join(profile_data['likes'])}")
                if profile_data.get("pet"):
                    pet = profile_data['pet']
                    profile_items.append(f"ä»–/å¥¹æœ‰ä¸€éš»å«åšã€Œ{pet.get('name', '')}ã€çš„{pet.get('type', 'å¯µç‰©')}")
                
                if profile_items:
                    user_profile_str = f"\n\n**é—œæ–¼é€™ä½æœ‹å‹çš„èƒŒæ™¯è³‡è¨Šï¼ˆè«‹åœ¨å°è©±ä¸­è‡ªç„¶åœ°é‹ç”¨ï¼Œä¸è¦ç›´æ¥èªªå‡ºä½ è¨˜å¾—ï¼‰**ï¼š\n- {'\n- '.join(profile_items)}"

        # å°‡å€‹äººåŒ–æç¤ºå’ŒåŸå§‹ç³»çµ±æç¤ºçµåˆ
        personalized_system_instruction = SYSTEM_INSTRUCTION + user_profile_str
        
        # ä½¿ç”¨å€‹äººåŒ–æç¤ºä¾†åˆå§‹åŒ–æ¨¡å‹
        chat_model = genai.GenerativeModel(
            'gemini-2.5-flash',
            system_instruction=personalized_system_instruction,
        )
        # --- â­ æ–°å¢çš„éƒ¨åˆ†çµæŸ â­ ---

        logging.info(f"æ”¶åˆ°ä¾†è‡ª User ID: {user_id} çš„èŠå¤©è«‹æ±‚")
        
        gemini_history_for_chat = process_history_for_gemini(history[:-1])
        # ä½¿ç”¨æ–°çš„ chat_model ä¾†é–‹å§‹å°è©±
        chat_session = chat_model.start_chat(history=gemini_history_for_chat) 

        latest_message_parts = process_history_for_gemini([history[-1]])[0]['parts']

        def generate_text_stream():
            response_stream = chat_session.send_message(latest_message_parts, stream=True)
            
            full_text_list = []
            for chunk in response_stream:
                if chunk.text:
                    yield chunk.text
                    full_text_list.append(chunk.text)
            
            final_text = "".join(full_text_list)
            logging.info(f"User ID: {user_id} çš„å›æ‡‰æ–‡å­—å·²ç”Ÿæˆ: '{final_text[:50]}...'")

            if redis_client:
                try:
                    # å„²å­˜å®Œæ•´çš„å°è©±æ­·å²
                    pickled_history_to_save = pickle.dumps(chat_session.history)
                    redis_client.set(f"history:{user_id}", pickled_history_to_save, ex=86400) # åŠ ä¸Šå‰ç¶´ä»¥å€åˆ†
                    logging.info(f"å·²å°‡ User ID: {user_id} çš„å°è©±æ­·å²æ›´æ–°è‡³ Redisã€‚")

                    # --- â­ æ–°å¢ï¼šåœ¨èƒŒæ™¯åŸ·è¡Œå€‹äººæª”æ¡ˆæ›´æ–° â­ ---
                    # æˆ‘å€‘å°‡ chat_session.history å‚³éçµ¦åˆ†æå‡½å¼
                    # ä½¿ç”¨ threading é¿å…é˜»å¡ä¸»å›æ‡‰æµç¨‹
                    analysis_thread = Thread(target=update_user_profile, args=(user_id, chat_session.history))
                    analysis_thread.start()
                    
                except Exception as e:
                    logging.error(f"å„²å­˜ history è‡³ Redis å¤±æ•—: {e}")

        return Response(stream_with_context(generate_text_stream()), mimetype='text/plain; charset=utf-8')

    except Exception as e:
        logging.critical(f"--- åœ¨ /api/chat ä¸­ç™¼ç”Ÿæœªè™•ç†çš„ä¾‹å¤–: {e} ---", exc_info=True)
        return Response("ä¼ºæœå™¨å…§éƒ¨ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤", status=500)

@app.route('/api/speech', methods=['POST'])
def speech():
    """
    æ­¤ç«¯é»ç¾åœ¨æœƒè‡ªå‹•è™•ç†ç¹è½‰ç°¡ã€‚
    """
    try:
        data = request.json
        text = data.get("text")

        if not text:
            return jsonify({"error": "text ä¸å¯ç‚ºç©º"}), 400

        # æ¸…ç†æ–‡å­—ï¼Œç§»é™¤ä¸é©åˆèªéŸ³åˆæˆçš„å­—å…ƒ
        # æ³¨æ„ï¼šæˆ‘å€‘å…ˆæ¸…ç†å†è½‰æ›ï¼Œæˆ–è€…å…ˆè½‰æ›å†æ¸…ç†ï¼Œå½±éŸ¿ä¸å¤§ã€‚
        # é€™è£¡çš„é †åºæ˜¯å…ˆæ¸…ç†å†é€å»è½‰æ›ã€‚
        text_for_speech = cleanup_text_for_speech(text)
        
        audio_base64 = text_to_speech_azure(text_for_speech)

        if audio_base64:
            return jsonify({"audio_base64": audio_base64})
        else:
            return jsonify({"error": "èªéŸ³åˆæˆå¤±æ•—"}), 500

    except Exception as e:
        logging.critical(f"--- åœ¨ /api/speech ä¸­ç™¼ç”Ÿæœªè™•ç†çš„ä¾‹å¤–: {e} ---", exc_info=True)
        return Response("ä¼ºæœå™¨å…§éƒ¨ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤", status=500)


if __name__ == '__main__':
    app.run(host='0.0.0.0', port=int(os.getenv('PORT', 8080)), debug=True)